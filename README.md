# **ğŸ“š Agente Inteligente de RecomendaciÃ³n de Libros**

## **ğŸ“‹ DescripciÃ³n del Proyecto**

Este proyecto implementa un **Agente Inteligente de RecomendaciÃ³n** basado en Deep Learning utilizando Python y TensorFlow/Keras.

A diferencia de un modelo de regresiÃ³n tradicional, este agente no se limita a predecir una calificaciÃ³n aislada. Su objetivo principal es **simular un proceso de toma de decisiones**: el agente analiza un conjunto de libros candidatos para un usuario especÃ­fico, predice el nivel de satisfacciÃ³n para cada uno y **recomienda activamente** la mejor opciÃ³n (Top-1 Recommendation).

El sistema utiliza una **arquitectura hÃ­brida** que combina:

1. **Filtrado Colaborativo Neural (NCF):** Aprende patrones latentes de las preferencias histÃ³ricas del usuario y su interacciÃ³n con los libros.  
2. **Filtrado Basado en Contenido (NLP):** Utiliza procesamiento de lenguaje natural para analizar semÃ¡nticamente las descripciones de los libros, permitiendo recomendar tÃ­tulos basÃ¡ndose en su temÃ¡tica y no solo en su popularidad.  
1. 

## **ğŸ—‚ï¸ Dataset**

El conjunto de datos original consta de dos fuentes principales:

* books\_data.csv: Metadatos de los libros (tÃ­tulo, descripciÃ³n, autores, categorÃ­as).  
* Books\_rating.csv: Interacciones de usuarios (User\_ID, Book\_ID, Score).

Dataset obtenido del website Kaggle: *https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews/data*

Para el Notebook de Collab (TrabajoFinal_Agentes_Inteligentes.jpynb) subimos el archivo books_data.csv directamente a Collab, pero para Books_rating.csv tuvimos que subir el archivo a Google Drive y montamos la ruta en Collab.

Se hicieron las modificaciones para el archivo .py para usar una ruta local data_storage.

Los archivos no se subieron a GitHub debido al gran tamaÃ±o de los mismos. Se recomienda hacer la descarga local desde la web indicada.

**EstadÃ­sticas del Procesamiento:**

* Se cargÃ³ una muestra inicial de 100,000 registros para optimizar el rendimiento.  
* **Limpieza:** Se eliminaron columnas irrelevantes (imÃ¡genes, links) y filas con valores nulos en campos crÃ­ticos.  
* **Datos Finales:** El dataset limpio para entrenamiento consta de aproximadamente **68,930 muestras** de alta calidad.

## **ğŸ› ï¸ MetodologÃ­a y Pipeline**

### **1\. Preprocesamiento de Datos**

* **EstandarizaciÃ³n:** NormalizaciÃ³n de tÃ­tulos (minÃºsculas y guiones bajos) para garantizar la consistencia en la combinaciÃ³n de datos (Merge).  
* **CodificaciÃ³n de Etiquetas (Label Encoding):** TransformaciÃ³n de User\_id y Title a secuencias de nÃºmeros enteros Ãºnicos para ser procesados por los Embeddings.  
* **Procesamiento de Lenguaje Natural (NLP):**  
  * TokenizaciÃ³n de descripciones (Vocabulario: 10,000 palabras mÃ¡s frecuentes).  
  * Padding de secuencias a una longitud fija de 100 palabras.

### **2\. Arquitectura del Modelo (Deep Learning)**

Se diseÃ±Ã³ una red neuronal con la API Funcional de Keras que consta de tres ramas de entrada:

1. **Vector de Usuario:** Input (1) \- \- \- \> Embedding (Dim 16\) \- \- \- \> Flatten.  
2. **Vector de Libro:** Input (1) \- \- \- \> Embedding (Dim 16\) \- \- \- \> Flatten.  
3. **Vector de DescripciÃ³n:** Input (100) \- \- \- \>Text Embedding (Dim 16\) \- \- \- \> Global Average Pooling.

FusiÃ³n: Los tres vectores  se concatenan y pasan por capas densas (Dense 64 \- \- \- \> Dense 16\) con activaciÃ³n ReLU para aprender relaciones no lineales complejas.

Salida: Una neurona con activaciÃ³n lineal (RegresiÃ³n) para predecir el puntaje (1.0 a 5.0).

### **ğŸ“‰ AnÃ¡lisis de Mejora del Modelo: Combatiendo el Overfitting**

#### **1\. El Problema Detectado: Overfitting (Sobreajuste)**

En la primera versiÃ³n del modelo, observamos un comportamiento clÃ¡sico de **Sobreajuste** con una brecha muy alta entre entrenamiento y validaciÃ³n.

* **Evidencia NumÃ©rica:**  
  * **Training Loss (Entrenamiento):** CayÃ³ hasta **\~0.15**.  
  * **Validation Loss (Prueba):** Se estancÃ³ en **\~1.25**.  
  * **La Brecha:** ExistÃ­a una diferencia de **1.1 puntos**. Esto indica que el modelo estaba "memorizando" el set de entrenamiento casi a la perfecciÃ³n, pero fallaba notablemente al generalizar.  
* **DiagnÃ³stico:** El modelo tenÃ­a demasiada capacidad. En lugar de aprender patrones generales, estaba memorizando cada calificaciÃ³n individual.

#### **2\. La SoluciÃ³n: Estrategias de RegularizaciÃ³n**

Para solucionar esto, aplicamos tres tÃ©cnicas de regularizaciÃ³n diseÃ±adas para "dificultar" el aprendizaje y forzar al modelo a generalizar:

* **RegularizaciÃ³n L2 (Ridge):** AÃ±adimos `kernel_regularizer=l2(0.01)` para penalizar pesos grandes, obligando a la red a buscar patrones mÃ¡s simples.  
* **Capas de Dropout (Abandono):** Insertamos `Dropout(0.5)` para apagar aleatoriamente el 50% de las neuronas en cada paso, evitando la co-dependencia.  
* **ReducciÃ³n de Complejidad:** Redujimos los Embeddings (de 32 a 16\) y las capas â€œDenseâ€ (de 128 a 64\) para limitar la "capacidad de memoria" del modelo.

#### **3\. El Resultado: EstabilizaciÃ³n y Robustez**

Tras aplicar estos cambios, las curvas de aprendizaje mostraron una mejora crÃ­tica en la estabilidad:

* **Cierre de la Brecha (Gap):**  
  * **Training Loss Actual:** SubiÃ³ a **\~1.30** (ya no memoriza).  
  * **Validation Loss Actual:** Se situÃ³ en **\~1.58**.  
  * **Mejora:** La brecha se redujo de 1.1 a solo **0.28**. Las lÃ­neas ahora se mueven juntas.  
* **Trade-off (Costo-Beneficio):**  
  * El **RMSE** subiÃ³ ligeramente de **1.08** a **1.12**.  
  * *InterpretaciÃ³n:* Aunque el error numÃ©rico es un poco mÃ¡s alto, el modelo es **honesto**. Un RMSE de 1.12 con una brecha pequeÃ±a es infinitamente mejor que un RMSE de 1.08 logrado mediante "trampa" (memorizaciÃ³n), ya que el nuevo modelo funcionarÃ¡ de manera predecible con usuarios reales.

## **ğŸ“Š Resultados y EvaluaciÃ³n**

El modelo fue entrenado durante un maximo de 10 Epochs con un tamaÃ±o de batch de 32\. Se agregÃ³ un Early Stop para mejorar el resultado y ayudar a bajar el Overfitting.

* **MÃ©trica de EvaluaciÃ³n:** RMSE (Root Mean Squared Error).  
* **InterpretaciÃ³n:** El RMSE indica, en promedio, quÃ© tan alejada estÃ¡ la predicciÃ³n del modelo (en estrellas) respecto a la calificaciÃ³n real del usuario.

*Ejemplo de inferencia del Agente:*

**ğŸ¤– Resultado del Agente**

**ğŸ‘¤ Usuario Elegido:** `AVZO523PH9I81`
*ğŸ” El agente estÃ¡ analizando aleatoriamente 5 libros para este usuario...*

| Book Title | Predicted Rating |
| :--- | :--- |
| Of Mice And Men (Penguin Audiobooks) | 4.52 |
| Resurrection Day | 4.12 |
| Inquest On The Shroud Of Turin: Latest Scientific Findings | 4.34 |
| You Can'T Go Home Again | 4.02 |
| ğŸŒŸ **The Mayor Of Casterbridge (Signet Classical Books)** | **4.53 (Libro Ganador)** |

---

> **âœ… RecomendaciÃ³n Final del Agente:** TÃº deberÃ­as leer *'The Mayor Of Casterbridge (Signet Classical Books)'*


## **ğŸ’» TecnologÃ­as Utilizadas**

* **Lenguaje:** Python 3.10.8
* **LibrerÃ­as Principales:**  
  * TensorFlow / Keras: ConstrucciÃ³n y entrenamiento de la red neuronal.  
  * Pandas: ManipulaciÃ³n y limpieza de datos.  
  * Scikit-Learn: Preprocesamiento (LabelEncoder) y divisiÃ³n de datos (Train/Test Split).  
  * Matplotlib: VisualizaciÃ³n de curvas de aprendizaje.

## **ğŸš€ Instrucciones de EjecuciÃ³n**

1. Clonar el repositorio.  
2. Asegurarse de tener los archivos CSV en la ruta especificada (sample\_data/ y drive/MyDrive/project\_data/).  
3. Instalar las dependencias necesarias:  
   pip install pandas numpy tensorflow scikit-learn matplotlib  
4. Ejecutar el notebook o script principal.

---

*Proyecto desarrollado como parte del curso de Agentes Inteligentes.*

