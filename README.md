# **üìö Agente Inteligente de Recomendaci√≥n de Libros**

## **üìã Descripci√≥n del Proyecto**

Este proyecto implementa un **Agente Inteligente de Recomendaci√≥n** basado en Deep Learning utilizando Python y TensorFlow/Keras.

A diferencia de un modelo de regresi√≥n tradicional, este agente no se limita a predecir una calificaci√≥n aislada. Su objetivo principal es **simular un proceso de toma de decisiones**: el agente analiza un conjunto de libros candidatos para un usuario espec√≠fico, predice el nivel de satisfacci√≥n para cada uno y **recomienda activamente** la mejor opci√≥n (Top-1 Recommendation).

El sistema utiliza una **arquitectura h√≠brida** que combina:

1. **Filtrado Colaborativo Neural (NCF):** Aprende patrones latentes de las preferencias hist√≥ricas del usuario y su interacci√≥n con los libros.  
2. **Filtrado Basado en Contenido (NLP):** Utiliza procesamiento de lenguaje natural para analizar sem√°nticamente las descripciones de los libros, permitiendo recomendar t√≠tulos bas√°ndose en su tem√°tica y no solo en su popularidad.  
1. 

## **üóÇÔ∏è Dataset**

El conjunto de datos original consta de dos fuentes principales:

* books\_data.csv: Metadatos de los libros (t√≠tulo, descripci√≥n, autores, categor√≠as).  
* Books\_rating.csv: Interacciones de usuarios (User\_ID, Book\_ID, Score).

Dataset obtenido del website Kaggle: *https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews/data*

**Estad√≠sticas del Procesamiento:**

* Se carg√≥ una muestra inicial de 100,000 registros para optimizar el rendimiento.  
* **Limpieza:** Se eliminaron columnas irrelevantes (im√°genes, links) y filas con valores nulos en campos cr√≠ticos.  
* **Datos Finales:** El dataset limpio para entrenamiento consta de aproximadamente **68,930 muestras** de alta calidad.

## **üõ†Ô∏è Metodolog√≠a y Pipeline**

### **1\. Preprocesamiento de Datos**

* **Estandarizaci√≥n:** Normalizaci√≥n de t√≠tulos (min√∫sculas y guiones bajos) para garantizar la consistencia en la combinaci√≥n de datos (Merge).  
* **Codificaci√≥n de Etiquetas (Label Encoding):** Transformaci√≥n de User\_id y Title a secuencias de n√∫meros enteros √∫nicos para ser procesados por los Embeddings.  
* **Procesamiento de Lenguaje Natural (NLP):**  
  * Tokenizaci√≥n de descripciones (Vocabulario: 10,000 palabras m√°s frecuentes).  
  * Padding de secuencias a una longitud fija de 100 palabras.

### **2\. Arquitectura del Modelo (Deep Learning)**

Se dise√±√≥ una red neuronal con la API Funcional de Keras que consta de tres ramas de entrada:

1. **Vector de Usuario:** Input (1) \- \- \- \> Embedding (Dim 16\) \- \- \- \> Flatten.  
2. **Vector de Libro:** Input (1) \- \- \- \> Embedding (Dim 16\) \- \- \- \> Flatten.  
3. **Vector de Descripci√≥n:** Input (100) \- \- \- \>Text Embedding (Dim 16\) \- \- \- \> Global Average Pooling.

Fusi√≥n: Los tres vectores  se concatenan y pasan por capas densas (Dense 64 \- \- \- \> Dense 16\) con activaci√≥n ReLU para aprender relaciones no lineales complejas.

Salida: Una neurona con activaci√≥n lineal (Regresi√≥n) para predecir el puntaje (1.0 a 5.0).

### **üìâ An√°lisis de Mejora del Modelo: Combatiendo el Overfitting**

#### **1\. El Problema Detectado: Overfitting (Sobreajuste)**

En la primera versi√≥n del modelo, observamos un comportamiento cl√°sico de **Sobreajuste** con una brecha muy alta entre entrenamiento y validaci√≥n.

* **Evidencia Num√©rica:**  
  * **Training Loss (Entrenamiento):** Cay√≥ hasta **\~0.15**.  
  * **Validation Loss (Prueba):** Se estanc√≥ en **\~1.25**.  
  * **La Brecha:** Exist√≠a una diferencia de **1.1 puntos**. Esto indica que el modelo estaba "memorizando" el set de entrenamiento casi a la perfecci√≥n, pero fallaba notablemente al generalizar.  
* **Diagn√≥stico:** El modelo ten√≠a demasiada capacidad. En lugar de aprender patrones generales, estaba memorizando cada calificaci√≥n individual.

#### **2\. La Soluci√≥n: Estrategias de Regularizaci√≥n**

Para solucionar esto, aplicamos tres t√©cnicas de regularizaci√≥n dise√±adas para "dificultar" el aprendizaje y forzar al modelo a generalizar:

* **Regularizaci√≥n L2 (Ridge):** A√±adimos `kernel_regularizer=l2(0.01)` para penalizar pesos grandes, obligando a la red a buscar patrones m√°s simples.  
* **Capas de Dropout (Abandono):** Insertamos `Dropout(0.5)` para apagar aleatoriamente el 50% de las neuronas en cada paso, evitando la co-dependencia.  
* **Reducci√≥n de Complejidad:** Redujimos los Embeddings (de 32 a 16\) y las capas ‚ÄúDense‚Äù (de 128 a 64\) para limitar la "capacidad de memoria" del modelo.

#### **3\. El Resultado: Estabilizaci√≥n y Robustez**

Tras aplicar estos cambios, las curvas de aprendizaje mostraron una mejora cr√≠tica en la estabilidad:

* **Cierre de la Brecha (Gap):**  
  * **Training Loss Actual:** Subi√≥ a **\~1.30** (ya no memoriza).  
  * **Validation Loss Actual:** Se situ√≥ en **\~1.58**.  
  * **Mejora:** La brecha se redujo de 1.1 a solo **0.28**. Las l√≠neas ahora se mueven juntas.  
* **Trade-off (Costo-Beneficio):**  
  * El **RMSE** subi√≥ ligeramente de **1.08** a **1.12**.  
  * *Interpretaci√≥n:* Aunque el error num√©rico es un poco m√°s alto, el modelo es **honesto**. Un RMSE de 1.12 con una brecha peque√±a es infinitamente mejor que un RMSE de 1.08 logrado mediante "trampa" (memorizaci√≥n), ya que el nuevo modelo funcionar√° de manera predecible con usuarios reales.

## **üìä Resultados y Evaluaci√≥n**

El modelo fue entrenado durante un maximo de 10 Epochs con un tama√±o de batch de 32\. Se agreg√≥ un Early Stop para mejorar el resultado y ayudar a bajar el Overfitting.

* **M√©trica de Evaluaci√≥n:** RMSE (Root Mean Squared Error).  
* **Interpretaci√≥n:** El RMSE indica, en promedio, qu√© tan alejada est√° la predicci√≥n del modelo (en estrellas) respecto a la calificaci√≥n real del usuario.

*Ejemplo de inferencia del Agente:*

Plaintext  
\--- Agente de Recomendaci√≥n \---  
Libro: dr.\_seuss:\_american\_icon  
Rating Real del Usuario: 5.0 estrellas  
Predicci√≥n del Agente: 4.82 estrellas  
Veredicto del Agente: ¬°Altamente Recomendado\! üåü

## **üíª Tecnolog√≠as Utilizadas**

* **Lenguaje:** Python 3.x  
* **Librer√≠as Principales:**  
  * TensorFlow / Keras: Construcci√≥n y entrenamiento de la red neuronal.  
  * Pandas: Manipulaci√≥n y limpieza de datos.  
  * Scikit-Learn: Preprocesamiento (LabelEncoder) y divisi√≥n de datos (Train/Test Split).  
  * Matplotlib: Visualizaci√≥n de curvas de aprendizaje.

## **üöÄ Instrucciones de Ejecuci√≥n**

1. Clonar el repositorio.  
2. Asegurarse de tener los archivos CSV en la ruta especificada (sample\_data/ y drive/MyDrive/project\_data/).  
3. Instalar las dependencias necesarias:  
   pip install pandas numpy tensorflow scikit-learn matplotlib  
4. Ejecutar el notebook o script principal.

---

*Proyecto desarrollado como parte del curso de Agentes Inteligentes.*

